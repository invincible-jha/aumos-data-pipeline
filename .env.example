# ============================================================================
# .env.example â€” AumOS Data Pipeline Service
# Copy to .env and fill in values for local development
# ============================================================================

# Core service identity
AUMOS_SERVICE_NAME=aumos-data-pipeline
AUMOS_ENVIRONMENT=development

# Database (PostgreSQL)
DATABASE_URL=postgresql+asyncpg://aumos:aumos_dev@localhost:5432/aumos
AUMOS_DPL_DB_POOL_SIZE=10
AUMOS_DPL_DB_MAX_OVERFLOW=20

# Kafka (event streaming)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP_ID=aumos-data-pipeline

# Redis (caching / job state)
REDIS_URL=redis://localhost:6379/0

# MinIO / S3 (object storage for datasets and artifacts)
MINIO_ENDPOINT=http://localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=aumos-data
AWS_DEFAULT_REGION=us-east-1

# Airflow (orchestration)
AIRFLOW_URL=http://localhost:8080
AIRFLOW_USERNAME=aumos
AIRFLOW_PASSWORD=aumos_dev

# DVC (data versioning)
DVC_REMOTE_URL=s3://aumos-data/dvc
DVC_REMOTE_ENDPOINT_URL=http://localhost:9000

# JWT / Auth (shared with aumos-auth-gateway)
AUMOS_JWT_SECRET=change-me-in-production-use-256-bit-key
AUMOS_JWT_ALGORITHM=HS256

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Pipeline defaults
AUMOS_DPL_MAX_FILE_SIZE_MB=1024
AUMOS_DPL_BATCH_SIZE=10000
AUMOS_DPL_QUALITY_SCORE_THRESHOLD=0.8
AUMOS_DPL_DEFAULT_PARQUET_COMPRESSION=snappy
